{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport time\nimport shutil\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T09:54:27.717305Z","iopub.execute_input":"2022-04-21T09:54:27.717573Z","iopub.status.idle":"2022-04-21T09:54:31.570606Z","shell.execute_reply.started":"2022-04-21T09:54:27.717545Z","shell.execute_reply":"2022-04-21T09:54:31.569628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Since we're dealing with image files which are big files, GPU will be used for enhanced performance in terms of computations\n#Using Kaggle IDE, GPU is integrated & has been activated\n#Checking GPU Activation / Listing number of GPU\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\nprint(\"Num GPUs Available: \", len(physical_devices))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:31.572467Z","iopub.execute_input":"2022-04-21T09:54:31.572763Z","iopub.status.idle":"2022-04-21T09:54:31.721316Z","shell.execute_reply.started":"2022-04-21T09:54:31.572724Z","shell.execute_reply":"2022-04-21T09:54:31.719796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#display working dir\nos.listdir('./')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:31.723018Z","iopub.execute_input":"2022-04-21T09:54:31.723925Z","iopub.status.idle":"2022-04-21T09:54:31.731777Z","shell.execute_reply.started":"2022-04-21T09:54:31.723834Z","shell.execute_reply":"2022-04-21T09:54:31.731027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this is where the ds is stored\nos.listdir('/kaggle/input/')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:31.733015Z","iopub.execute_input":"2022-04-21T09:54:31.733584Z","iopub.status.idle":"2022-04-21T09:54:31.741725Z","shell.execute_reply.started":"2022-04-21T09:54:31.73355Z","shell.execute_reply":"2022-04-21T09:54:31.740978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing important libs\nimport numpy as np #mathematical fn\nimport pandas as pd #data manipulation /analysis\nimport seaborn as sns #statistical data viz\nsns.set_style('darkgrid')\n\nimport glob #file/path retreival matching pattern\nimport matplotlib.pyplot as plt #ploting interface\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:31.743589Z","iopub.execute_input":"2022-04-21T09:54:31.744426Z","iopub.status.idle":"2022-04-21T09:54:31.856338Z","shell.execute_reply.started":"2022-04-21T09:54:31.744389Z","shell.execute_reply":"2022-04-21T09:54:31.855692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm #tracking bar\n\n#from matplotlib.pyplot import imshow #image in grayscale\n\nfrom IPython.core.display import display, HTML\n\nfrom PIL import Image #To represent Python Imaging Lib Image\nfrom sklearn.metrics import confusion_matrix, classification_report #evaluation stage","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:31.85782Z","iopub.execute_input":"2022-04-21T09:54:31.857997Z","iopub.status.idle":"2022-04-21T09:54:31.863046Z","shell.execute_reply.started":"2022-04-21T09:54:31.857974Z","shell.execute_reply":"2022-04-21T09:54:31.862164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#NOW let's verify class distribution\n# NB: It is important to have a balanced / non-biased dataset  - to prevent model frombeing biased to majority class\n\ntrain_image_names = glob.glob('../input/foodnonfood/TRAIN/TRAIN/*/*.jpg') #READING OF TRAINIiNG imgs from path\nprint(\"Total number of training images: \", len(train_image_names))","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:31.864461Z","iopub.execute_input":"2022-04-21T09:54:31.864872Z","iopub.status.idle":"2022-04-21T09:54:33.195361Z","shell.execute_reply.started":"2022-04-21T09:54:31.864835Z","shell.execute_reply":"2022-04-21T09:54:33.193906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make train_image_names as series object\ntrain_image_names = pd.Series(train_image_names)\ntrain_df = pd.DataFrame()\n\n# generate Filename field\ntrain_df['Filename'] = train_image_names.map(lambda img_name: img_name.split(\"/\")[-1])\n\n# generate ClassId field\ntrain_df['ClassId'] = train_image_names.map(lambda img_name: (img_name.split(\"/\")[-2]))\nclass_id_distribution = train_df['ClassId'].value_counts()\nclass_id_distribution\n\n#we can already see that the data is almost balance with food class slightly bigger","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:33.196815Z","iopub.execute_input":"2022-04-21T09:54:33.197056Z","iopub.status.idle":"2022-04-21T09:54:33.236663Z","shell.execute_reply.started":"2022-04-21T09:54:33.197023Z","shell.execute_reply":"2022-04-21T09:54:33.235856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now let's visualize the classes in the training; Here we see that the classes are balanced\n\nplt.figure(figsize=(10,5))\nplt.bar(class_id_distribution.index, class_id_distribution.values, color=['salmon','cornflowerblue'])\nplt.title(label=\"Training Set Distribution\")\nplt.xlabel(('Food                                    Vs                                      Non Food'))\nplt.show()       \n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:33.238107Z","iopub.execute_input":"2022-04-21T09:54:33.238387Z","iopub.status.idle":"2022-04-21T09:54:33.436677Z","shell.execute_reply.started":"2022-04-21T09:54:33.238353Z","shell.execute_reply":"2022-04-21T09:54:33.436025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TEST dataset\ntest = glob.glob('../input/foodnonfood/TEST/TEST/*/*.jpg')\nprint(\"Total number of test images: \", len(test))\n\n# make train_image_names as serie object\ntest = pd.Series(test)\ntestdf = pd.DataFrame()\n\n# generate Filename field\ntestdf['Filename'] = test.map(lambda img_name: img_name.split(\"/\")[-1])\n\n# generate ClassId field\ntestdf['ClassId'] = test.map(lambda img_name: (img_name.split(\"/\")[-2]))\nclass_id_distribution2 = testdf['ClassId'].value_counts()\nclass_id_distribution2","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:33.437852Z","iopub.execute_input":"2022-04-21T09:54:33.43809Z","iopub.status.idle":"2022-04-21T09:54:34.207564Z","shell.execute_reply.started":"2022-04-21T09:54:33.438061Z","shell.execute_reply":"2022-04-21T09:54:34.206853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.bar(class_id_distribution2.index, class_id_distribution2.values, color=['salmon','cornflowerblue'])\nplt.title(label=\"Test Set Distribution\")\nplt.xlabel(('Food                                    Vs                                      Non Food'))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:34.20901Z","iopub.execute_input":"2022-04-21T09:54:34.209504Z","iopub.status.idle":"2022-04-21T09:54:34.381222Z","shell.execute_reply.started":"2022-04-21T09:54:34.209466Z","shell.execute_reply":"2022-04-21T09:54:34.380581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that the data distribution was checked, we saw that the data does not have high bias. Also, our data will be taken in random batches to ensure biasness is not a problem","metadata":{}},{"cell_type":"code","source":"\n#Lets import some ML Libs\n\nfrom tensorflow import keras #AI interface for TF Lib\n# from tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, GlobalAveragePooling2D, MaxPooling2D,BatchNormalization, Flatten #used in DL model layers\nfrom tensorflow.keras.optimizers import Adam, Adamax, RMSprop #to optimize performance\nfrom tensorflow.keras.metrics import categorical_crossentropy #Computes the crossentropy metric between the labels and predictions.\nfrom tensorflow.keras import regularizers # Regularizers for applying penalties on layer parameters during optimization.\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator #For generating image Batches (with augmentation)\nfrom tensorflow.keras.models import Model, load_model, Sequential #seq to group layer stacks linearly into a Model (tf.keras.Model)\nfrom tensorflow.keras.applications import imagenet_utils\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:34.382545Z","iopub.execute_input":"2022-04-21T09:54:34.382779Z","iopub.status.idle":"2022-04-21T09:54:35.203389Z","shell.execute_reply.started":"2022-04-21T09:54:34.382746Z","shell.execute_reply":"2022-04-21T09:54:35.202512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#as all data need to be pre-processed, here Data augmentation is used to produce favourable results\n#Augmentation using ImageData Generator\ntrain='../input/foodnonfood/TRAIN/TRAIN'\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255, #to transform every pixel value from range [0,255] -> [0,1]\n        shear_range=0.2,#shifting the pixels horizontally\n        zoom_range=0.2,\n        rotation_range=90,\n        horizontal_flip=True,\n        fill_mode='nearest')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:35.204761Z","iopub.execute_input":"2022-04-21T09:54:35.205011Z","iopub.status.idle":"2022-04-21T09:54:35.212123Z","shell.execute_reply.started":"2022-04-21T09:54:35.204976Z","shell.execute_reply":"2022-04-21T09:54:35.211473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#a batch size of 32/64 is an optimum size - smaller batches are better for  stability (Brownlee,2019)\n#reading the training images\ntraining_set = train_datagen.flow_from_directory(\n                    train,\n                    target_size=(224, 224),\n                    batch_size=64,\n                    class_mode='binary')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:35.217035Z","iopub.execute_input":"2022-04-21T09:54:35.217517Z","iopub.status.idle":"2022-04-21T09:54:45.887556Z","shell.execute_reply.started":"2022-04-21T09:54:35.21748Z","shell.execute_reply":"2022-04-21T09:54:45.886801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading test img\ntest='../input/foodnonfood/TEST/TEST'\ntest_datagen=ImageDataGenerator(rescale=1./255)\ntestset=test_datagen.flow_from_directory(test,target_size=(224,224),batch_size=32,class_mode='binary')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:45.888699Z","iopub.execute_input":"2022-04-21T09:54:45.889081Z","iopub.status.idle":"2022-04-21T09:54:48.698471Z","shell.execute_reply.started":"2022-04-21T09:54:45.889043Z","shell.execute_reply":"2022-04-21T09:54:48.697042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that the data has been augemented, let's visualise the images in the DS","metadata":{}},{"cell_type":"code","source":"#First let's visualize the Train set\nplt.figure(figsize=(15, 15)) #image displayed in size 15X15\nfor i in range(0, 10):\n    plt.subplot(2, 5, i+1) #2 rows with 5 images per row\n    for X_batch, Y_batch in training_set:\n        image = X_batch[0]        \n        dic = {1:'food', 0:'non-food'} \n        plt.title(dic.get(Y_batch[0]))\n        plt.axis('off')\n        plt.imshow(np.squeeze(image),interpolation='nearest') # nearest will display an image without trying to interpolate between pixels since output display resolution != image resolution\n        break\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:54:48.699755Z","iopub.execute_input":"2022-04-21T09:54:48.699995Z","iopub.status.idle":"2022-04-21T09:55:01.136551Z","shell.execute_reply.started":"2022-04-21T09:54:48.699961Z","shell.execute_reply":"2022-04-21T09:55:01.134256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Images all have different orientation but the image are all of good quality ","metadata":{}},{"cell_type":"code","source":"#Let's visualize the testset\n\nplt.figure(figsize=(15, 15)) #image displayed in size 15X15\nfor i in range(0, 10):\n    plt.subplot(2, 5, i+1) #2 rows with 5 images per row\n    for X_batch, Y_batch in testset:\n        image = X_batch[0]        \n        dic = {1:'food', 0:'non-food'} \n        plt.title(dic.get(Y_batch[0]))\n        plt.axis('off')\n        plt.imshow(np.squeeze(image),interpolation='nearest') # nearest will display an image without trying to interpolate between pixels since output display resolution != image resolution\n        break\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:55:01.137493Z","iopub.execute_input":"2022-04-21T09:55:01.137775Z","iopub.status.idle":"2022-04-21T09:55:05.540577Z","shell.execute_reply.started":"2022-04-21T09:55:01.137734Z","shell.execute_reply":"2022-04-21T09:55:05.537602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shape of the sets\nprint(\"training set shape is\",training_set[-1])\nprint(\"test set shape is\",testset[-1])\n\n#verifying current image shapes\nprint(\"training images shape is\",training_set.image_shape)\nprint(\"test images shape is\",testset.image_shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:55:05.54174Z","iopub.execute_input":"2022-04-21T09:55:05.542454Z","iopub.status.idle":"2022-04-21T09:55:05.550804Z","shell.execute_reply.started":"2022-04-21T09:55:05.542418Z","shell.execute_reply":"2022-04-21T09:55:05.549963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's build the model","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, MaxPooling2D #layers to be used in the CNN arch","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:55:05.552213Z","iopub.execute_input":"2022-04-21T09:55:05.553036Z","iopub.status.idle":"2022-04-21T09:55:05.557948Z","shell.execute_reply.started":"2022-04-21T09:55:05.553Z","shell.execute_reply":"2022-04-21T09:55:05.557149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1= Sequential()\nmodel1.add(tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=[224,224,3]))#images are RGB so last dimension is 3\nmodel1.add(MaxPool2D(pool_size=2,strides=2))\nmodel1.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\nmodel1.add(MaxPool2D(pool_size=2,strides=2))\nmodel1.add(Conv2D(filters=128,kernel_size=(3,3),activation='relu'))\nmodel1.add(MaxPool2D(pool_size=2,strides=2))\nmodel1.add(Conv2D(filters=256,kernel_size=(3,3),activation='relu'))\nmodel1.add(Conv2D(filters=256,kernel_size=(3,3),activation='relu'))\nmodel1.add(MaxPool2D(pool_size=2,strides=2))\nmodel1.add(Conv2D(filters=512,kernel_size=(3,3),activation='relu'))\nmodel1.add(Conv2D(filters=512,kernel_size=(3,3),activation='relu'))\nmodel1.add(Conv2D(filters=512,kernel_size=(3,3),activation='relu'))\nmodel1.add(MaxPool2D(pool_size=2,strides=2))\n#model1.add(Dropout(0.2))\nmodel1.add(Flatten())#Flattening is No brainer and it simply converts a multi-dimensional object to one-dimensional by re-arranging the elements.\nmodel1.add(Dropout(0.2))\n#model1.add(Dense(units=1024,activation='relu'))\nmodel1.add(Dense(units=512,activation='relu'))\nmodel1.add(Dense(units=128,activation='relu'))\nmodel1.add(Dense(units=64,activation='relu'))\nmodel1.add(Dense(units=1,activation='sigmoid')) #only one output required","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:00:54.3604Z","iopub.execute_input":"2022-04-21T10:00:54.360948Z","iopub.status.idle":"2022-04-21T10:00:54.482327Z","shell.execute_reply.started":"2022-04-21T10:00:54.36091Z","shell.execute_reply":"2022-04-21T10:00:54.481583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Metrics for model\nMETS = [\n      \n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n]\n#compiling model\n#binary crossentropy used since this is binary classification model; output has only two classes\nmodel1.compile(optimizer='SGD',loss='binary_crossentropy',metrics=['accuracy',METS])\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:00:56.406746Z","iopub.execute_input":"2022-04-21T10:00:56.407302Z","iopub.status.idle":"2022-04-21T10:00:56.426598Z","shell.execute_reply.started":"2022-04-21T10:00:56.407268Z","shell.execute_reply":"2022-04-21T10:00:56.425926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:00:58.342513Z","iopub.execute_input":"2022-04-21T10:00:58.343067Z","iopub.status.idle":"2022-04-21T10:00:58.358455Z","shell.execute_reply.started":"2022-04-21T10:00:58.343027Z","shell.execute_reply":"2022-04-21T10:00:58.357773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model Plotting \nfrom tensorflow.keras.utils import plot_model\nplot_model(model1, show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:01:00.900998Z","iopub.execute_input":"2022-04-21T10:01:00.901296Z","iopub.status.idle":"2022-04-21T10:01:01.152052Z","shell.execute_reply.started":"2022-04-21T10:01:00.901264Z","shell.execute_reply":"2022-04-21T10:01:01.151184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"History = model1.fit(training_set,\n                      validation_data=(testset),\n                      epochs=25,\n                      callbacks=[EarlyStopping(monitor='val_accuracy',patience=10)]) \n#Using early stopping so that if the validation accuracy does not increase 5X conscutively\n#model is then stopped; i.e not all 25 epochs will be completed","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:01:05.10304Z","iopub.execute_input":"2022-04-21T10:01:05.103329Z","iopub.status.idle":"2022-04-21T11:16:03.494514Z","shell.execute_reply.started":"2022-04-21T10:01:05.103298Z","shell.execute_reply":"2022-04-21T11:16:03.49364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#*others used to catch other output being returned\n#evaluation of trained model onto the test set\nloss, acc, prec, recall, auc, *others = model1.evaluate(testset) \nacc","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:16:03.496709Z","iopub.execute_input":"2022-04-21T11:16:03.497092Z","iopub.status.idle":"2022-04-21T11:16:14.508348Z","shell.execute_reply.started":"2022-04-21T11:16:03.497047Z","shell.execute_reply":"2022-04-21T11:16:14.507551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's Plot the iterations for Model 1**","metadata":{}},{"cell_type":"code","source":"#Plot Accuracy\nplt.figure()\nplt.plot(History.history['accuracy'])\nplt.plot(History.history['val_accuracy'])\nplt.title('Model 1 model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'Test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:16:14.509714Z","iopub.execute_input":"2022-04-21T11:16:14.510485Z","iopub.status.idle":"2022-04-21T11:16:14.740617Z","shell.execute_reply.started":"2022-04-21T11:16:14.510445Z","shell.execute_reply":"2022-04-21T11:16:14.739975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot LOSS\n\nplt.figure()\nplt.plot(History.history['loss'])\nplt.plot(History.history['val_loss'])\nplt.title('Model 1  loss')\nplt.ylabel('Loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'Test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:16:14.742346Z","iopub.execute_input":"2022-04-21T11:16:14.743111Z","iopub.status.idle":"2022-04-21T11:16:14.958679Z","shell.execute_reply.started":"2022-04-21T11:16:14.743072Z","shell.execute_reply":"2022-04-21T11:16:14.958006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plots end here","metadata":{}},{"cell_type":"markdown","source":"Hyper Parameter Tuning\n","metadata":{}},{"cell_type":"code","source":"Tuned= Sequential()#lets make the model more complex to prevent underfit\nTuned.add(tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=[224,224,3],kernel_initializer='he_uniform'))\nTuned.add(MaxPool2D(pool_size=2,strides=2))\nTuned.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\nTuned.add(MaxPool2D(pool_size=2,strides=2))\nTuned.add(Conv2D(filters=128,kernel_size=(3,3),activation='relu'))\nTuned.add(Conv2D(filters=128,kernel_size=(3,3),activation='relu'))\nTuned.add(MaxPool2D(pool_size=2,strides=2))\nTuned.add(Conv2D(filters=256,kernel_size=(3,3),activation='relu'))\nTuned.add(Conv2D(filters=256,kernel_size=(3,3),activation='relu'))\nTuned.add(MaxPool2D(pool_size=2,strides=2))\nTuned.add(Conv2D(filters=512,kernel_size=(3,3),activation='relu'))\nTuned.add(Conv2D(filters=512,kernel_size=(3,3),activation='relu'))\n#Tuned.add(MaxPool2D(pool_size=2,strides=2))\nTuned.add(Conv2D(filters=512,kernel_size=(3,3),activation='relu'))\nTuned.add(MaxPool2D(pool_size=2,strides=2))\nTuned.add(Dropout(0.2)) #add dropout to 0.2\nTuned.add(Flatten())\nTuned.add(Dropout(0.2))\nTuned.add(Dense(units=1024,activation='relu'))\nTuned.add(Dense(units=512,activation='relu'))\nTuned.add(Dense(units=128,activation='relu'))\nTuned.add(Dropout(0.2)) \nTuned.add(Dense(units=64,activation='relu'))\nTuned.add(Dense(units=1,activation='sigmoid')) #only one output required","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:20:26.495163Z","iopub.execute_input":"2022-04-21T11:20:26.495739Z","iopub.status.idle":"2022-04-21T11:20:26.633511Z","shell.execute_reply.started":"2022-04-21T11:20:26.495693Z","shell.execute_reply":"2022-04-21T11:20:26.632803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#opt = RMSprop(learning_rate= 0.00001, momentum=0.8, epsilon=1e-07)  #changing optimizer & adjust learning rate\n\nTuned.compile(loss='binary_crossentropy',\n              optimizer= 'Adamax',\n              metrics=['accuracy',METS])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:20:31.142924Z","iopub.execute_input":"2022-04-21T11:20:31.143175Z","iopub.status.idle":"2022-04-21T11:20:31.155474Z","shell.execute_reply.started":"2022-04-21T11:20:31.143146Z","shell.execute_reply":"2022-04-21T11:20:31.154671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Tuned.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:20:34.337382Z","iopub.execute_input":"2022-04-21T11:20:34.337953Z","iopub.status.idle":"2022-04-21T11:20:34.354562Z","shell.execute_reply.started":"2022-04-21T11:20:34.337914Z","shell.execute_reply":"2022-04-21T11:20:34.353881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(Tuned,show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:21:35.497832Z","iopub.execute_input":"2022-04-21T11:21:35.498087Z","iopub.status.idle":"2022-04-21T11:21:35.78045Z","shell.execute_reply.started":"2022-04-21T11:21:35.498058Z","shell.execute_reply":"2022-04-21T11:21:35.779672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"History2 = Tuned.fit(training_set,\n                      validation_data=(testset),\n                      epochs=100,#increase iterations\n                      callbacks=[EarlyStopping(monitor='val_accuracy',patience=10)]) \n#Using early stopping so that if the validation accuracy does not increase 10X conscutively\n#model is then stopped; i.e not all 100 epochs will be completed","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:21:41.605409Z","iopub.execute_input":"2022-04-21T11:21:41.606202Z","iopub.status.idle":"2022-04-21T13:27:47.21146Z","shell.execute_reply.started":"2022-04-21T11:21:41.606154Z","shell.execute_reply":"2022-04-21T13:27:47.210734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_tuned, acc_tuned, prec_tune,rec_tuned, auc_tuned,*others = Tuned.evaluate(testset) \nacc_tuned","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:28:34.236857Z","iopub.execute_input":"2022-04-21T13:28:34.237182Z","iopub.status.idle":"2022-04-21T13:28:45.027989Z","shell.execute_reply.started":"2022-04-21T13:28:34.237145Z","shell.execute_reply":"2022-04-21T13:28:45.027172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot Accuracy\nplt.figure()\nplt.plot(History2.history['accuracy'])\nplt.plot(History2.history['val_accuracy'])\nplt.title('Tuned model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'Test'], loc='upper left')\nplt.xlim([0,50])\nplt.ylim([0.0,1.2])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:29:00.424044Z","iopub.execute_input":"2022-04-21T13:29:00.424315Z","iopub.status.idle":"2022-04-21T13:29:00.640497Z","shell.execute_reply.started":"2022-04-21T13:29:00.424284Z","shell.execute_reply":"2022-04-21T13:29:00.639861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot LOSS\n\nplt.figure()\nplt.plot(History2.history['loss'])\nplt.plot(History2.history['val_loss'])\nplt.title('Tuned Model  loss')\nplt.ylabel('Loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'Test'], loc='upper left')\nplt.xlim([0,50])\nplt.ylim([0.0,1.2])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:29:14.648024Z","iopub.execute_input":"2022-04-21T13:29:14.648334Z","iopub.status.idle":"2022-04-21T13:29:14.886741Z","shell.execute_reply.started":"2022-04-21T13:29:14.648298Z","shell.execute_reply":"2022-04-21T13:29:14.88604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compare the models","metadata":{}},{"cell_type":"code","source":"#ACCURACY Evaluation\n\nplt.figure()\nplt.plot(History.history['accuracy'],label='Model 1 Train',linestyle='dashed')\nplt.plot(History.history['val_accuracy'],label='Model 1 Test')\nplt.plot(History2.history['accuracy'],label='Tuned  train',linestyle='dashed')\nplt.plot(History2.history['val_accuracy'],label='Tuned  Test')\nplt.title('Performance: ACCURACY',fontsize=20)\nplt.ylabel('Accuracy',fontsize=15)\nplt.xlabel('epoch',fontsize=15)\nplt.legend( loc='lower right',fontsize=15)\nplt.xlim([0,50])\nplt.ylim([0.0,1.2])\nplt.rcParams['figure.figsize'] = [15, 15]\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:30:03.021837Z","iopub.execute_input":"2022-04-21T13:30:03.022523Z","iopub.status.idle":"2022-04-21T13:30:03.270688Z","shell.execute_reply.started":"2022-04-21T13:30:03.022479Z","shell.execute_reply":"2022-04-21T13:30:03.270037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LOSS Evaluation\n\nplt.figure()\nplt.plot(History.history['loss'],label=' Model 1 Train',linestyle='dashed')\nplt.plot(History.history['val_loss'],label='MB Model Test')\nplt.plot(History2.history['loss'],label='Tuned Model train',linestyle='dashed')\nplt.plot(History2.history['val_loss'],label='Tuned Model Test')\nplt.title('Performance: LOSS',fontsize=20)\nplt.ylabel('LOSS',fontsize=15)\nplt.xlabel('epoch',fontsize=15)\nplt.legend( loc='upper left',fontsize=15)\nplt.xlim([0,50])\nplt.ylim([0.0,1.00])\nplt.rcParams['figure.figsize'] = [8, 8]\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:30:25.135317Z","iopub.execute_input":"2022-04-21T13:30:25.135577Z","iopub.status.idle":"2022-04-21T13:30:25.411295Z","shell.execute_reply.started":"2022-04-21T13:30:25.135547Z","shell.execute_reply":"2022-04-21T13:30:25.410603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets start the predictions","metadata":{}},{"cell_type":"code","source":"Prediction=Tuned.predict(testset,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:30:37.092402Z","iopub.execute_input":"2022-04-21T13:30:37.092649Z","iopub.status.idle":"2022-04-21T13:30:47.648088Z","shell.execute_reply.started":"2022-04-21T13:30:37.092621Z","shell.execute_reply":"2022-04-21T13:30:47.647393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"View the distribution of predictions","metadata":{}},{"cell_type":"code","source":"import scipy\nbins = [0.0,0.2,0.4,0.6,0.8,1.0]\nmn, std = scipy.stats.norm.fit(Prediction)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:30:47.649797Z","iopub.execute_input":"2022-04-21T13:30:47.650049Z","iopub.status.idle":"2022-04-21T13:30:47.656866Z","shell.execute_reply.started":"2022-04-21T13:30:47.650014Z","shell.execute_reply":"2022-04-21T13:30:47.655781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Mean of predictions= \",mn)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:30:47.658912Z","iopub.execute_input":"2022-04-21T13:30:47.65914Z","iopub.status.idle":"2022-04-21T13:30:47.665868Z","shell.execute_reply.started":"2022-04-21T13:30:47.65911Z","shell.execute_reply":"2022-04-21T13:30:47.665123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(Prediction,[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0])\nplt.title(\"histogram\") \nplt.xlim([0,1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:30:47.668087Z","iopub.execute_input":"2022-04-21T13:30:47.668659Z","iopub.status.idle":"2022-04-21T13:30:47.916715Z","shell.execute_reply.started":"2022-04-21T13:30:47.668595Z","shell.execute_reply":"2022-04-21T13:30:47.916039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets viz The images and corresponding predictions","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\nfor i in range(0+0,3+0):\n  plt.subplot(1, 3, (i-0)+1)\n  if Prediction[i, 0] >= 0.5: #0.5 can be a good cutoff val based on mean of preds\n      out = ('{:.2%} probability of being  Food case'.format(Prediction[i][0]))\n      \n      \n  else: \n      out = ('{:.2%} probability of being Non-Food case'.format(1-Prediction[i][0]))\n      \n      \n\n  plt.title(out+\"\\n Actual case : \"+ dic.get(Y_batch[i]))    \n  plt.imshow(np.squeeze(X_batch[i]))\n  plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:32:55.702264Z","iopub.execute_input":"2022-04-21T13:32:55.702524Z","iopub.status.idle":"2022-04-21T13:32:56.302231Z","shell.execute_reply.started":"2022-04-21T13:32:55.702495Z","shell.execute_reply":"2022-04-21T13:32:56.301573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testset.reset()\nx=np.concatenate([testset.next()[0] for i in range(testset.__len__())])\ny=np.concatenate([testset.next()[1] for i in range(testset.__len__())])\nprint(x.shape)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:33:08.815028Z","iopub.execute_input":"2022-04-21T13:33:08.815303Z","iopub.status.idle":"2022-04-21T13:33:27.944673Z","shell.execute_reply.started":"2022-04-21T13:33:08.815271Z","shell.execute_reply":"2022-04-21T13:33:27.943877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = Tuned.predict(testset,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:33:31.971051Z","iopub.execute_input":"2022-04-21T13:33:31.971742Z","iopub.status.idle":"2022-04-21T13:33:43.258727Z","shell.execute_reply.started":"2022-04-21T13:33:31.971705Z","shell.execute_reply":"2022-04-21T13:33:43.258007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = preds.copy()\npredictions[predictions <= 0.5] = 0\npredictions[predictions > 0.5] = 1","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:33:43.261793Z","iopub.execute_input":"2022-04-21T13:33:43.263314Z","iopub.status.idle":"2022-04-21T13:33:43.268256Z","shell.execute_reply.started":"2022-04-21T13:33:43.263284Z","shell.execute_reply":"2022-04-21T13:33:43.267478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_true=y,y_pred=predictions,target_names =['NONFOOD','FOOD']))","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:33:43.270475Z","iopub.execute_input":"2022-04-21T13:33:43.270906Z","iopub.status.idle":"2022-04-21T13:33:43.292484Z","shell.execute_reply.started":"2022-04-21T13:33:43.270872Z","shell.execute_reply":"2022-04-21T13:33:43.291838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\ncm = pd.DataFrame(data=confusion_matrix(y, predictions, labels=[0, 1]),index=[\"Actual Non Food\", \"Actual Food\"],\ncolumns=[\"Predicted Non Food\", \"Predicted Food\"])\nimport seaborn as sns\nsns.heatmap(cm,annot=True,fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:33:48.306Z","iopub.execute_input":"2022-04-21T13:33:48.306545Z","iopub.status.idle":"2022-04-21T13:33:48.540672Z","shell.execute_reply.started":"2022-04-21T13:33:48.306505Z","shell.execute_reply":"2022-04-21T13:33:48.540011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Tuned.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:36:07.298532Z","iopub.execute_input":"2022-04-21T13:36:07.299278Z","iopub.status.idle":"2022-04-21T13:36:07.31633Z","shell.execute_reply.started":"2022-04-21T13:36:07.299227Z","shell.execute_reply":"2022-04-21T13:36:07.315569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_layer='conv2d_50'","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:36:16.135763Z","iopub.execute_input":"2022-04-21T13:36:16.13607Z","iopub.status.idle":"2022-04-21T13:36:16.144852Z","shell.execute_reply.started":"2022-04-21T13:36:16.136032Z","shell.execute_reply":"2022-04-21T13:36:16.144047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GRAD CAM","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nimport cv2\n\n\ndef GradCam(model, imarr, layer_name, eps=1e-8): #epsil value def\n    \n\n    gMod = Model(\n\t\t\tinputs=[model.inputs],\n\t\t\toutputs=[model.get_layer(layer_name).output,\n\t\t\t\tmodel.output])\n    \n    with tf.GradientTape() as tape:\n      inputs = tf.cast(imarr, tf.float32)\n      (convOutputs, predictions) = gMod(inputs)\n      loss = predictions[:, 0]\n    gradientss = tape.gradient(loss, convOutputs)\n    \n    csCNVOut = tf.cast(convOutputs > 0, \"float32\")\n    csgradie = tf.cast(gradientss > 0, \"float32\")\n    guidedgradientss = csCNVOut * csgradie * gradientss\n    convOutputs = convOutputs[0]\n    guidedgradientss = guidedgradientss[0]\n    wgts = tf.reduce_mean(guidedgradientss, axis=(0, 1))\n    gdcam = tf.reduce_sum(tf.multiply(wgts, convOutputs), axis=-1)\n    (w, h) = (imarr.shape[2], imarr.shape[1])\n    hm = cv2.resize(gdcam.numpy(), (w, h))\n    numer = hm - np.min(hm)\n    denom = (hm.max() - hm.min()) + eps\n    hm = numer / denom\n    return hm\n\n\ndef sigmoid(x, a, b, c):\n    return c / (1 + np.exp(-a * (x-b)))\n\ndef supimp(img_bgr, gdcam, thresh, emphasize=False):\n    hm = cv2.resize(gdcam, (img_bgr.shape[1], img_bgr.shape[0]))\n    if emphasize:\n        hm = sigmoid(hm, 50, thresh, 1)\n    hm = np.uint8(255 * hm)\n    hm = cv2.applyColorMap(hm, cv2.COLORMAP_JET)\n    \n    hif = .8\n    supimpd_img = hm * hif + img_bgr * hif\n    supimpd_img = np.minimum(supimpd_img, 255.0).astype(np.uint8)  # scale 0 to 255  \n    supimpd_img_rgb = cv2.cvtColor(supimpd_img, cv2.COLOR_BGR2RGB)\n    #supimpd_img_rgb = supimpd_img\n    return supimpd_img_rgb","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:36:18.949818Z","iopub.execute_input":"2022-04-21T13:36:18.950072Z","iopub.status.idle":"2022-04-21T13:36:19.207985Z","shell.execute_reply.started":"2022-04-21T13:36:18.950042Z","shell.execute_reply":"2022-04-21T13:36:19.207242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"j=5","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:50:33.546008Z","iopub.execute_input":"2022-04-21T14:50:33.54629Z","iopub.status.idle":"2022-04-21T14:50:33.550805Z","shell.execute_reply.started":"2022-04-21T14:50:33.546258Z","shell.execute_reply":"2022-04-21T14:50:33.550109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MR=X_batch[j]","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:50:35.065712Z","iopub.execute_input":"2022-04-21T14:50:35.066436Z","iopub.status.idle":"2022-04-21T14:50:35.070516Z","shell.execute_reply.started":"2022-04-21T14:50:35.066397Z","shell.execute_reply":"2022-04-21T14:50:35.069691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(MR)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:50:36.449597Z","iopub.execute_input":"2022-04-21T14:50:36.4503Z","iopub.status.idle":"2022-04-21T14:50:36.891586Z","shell.execute_reply.started":"2022-04-21T14:50:36.450266Z","shell.execute_reply":"2022-04-21T14:50:36.891007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MR.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:36:31.776364Z","iopub.execute_input":"2022-04-21T13:36:31.777279Z","iopub.status.idle":"2022-04-21T13:36:31.783115Z","shell.execute_reply.started":"2022-04-21T13:36:31.777224Z","shell.execute_reply":"2022-04-21T13:36:31.782349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MRre = cv2.resize(MR,(224,224))     # resize image to match model's expected sizing\nMRre = np.reshape(MRre,[1,224,224,3]) ","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:50:40.629424Z","iopub.execute_input":"2022-04-21T14:50:40.630001Z","iopub.status.idle":"2022-04-21T14:50:40.636054Z","shell.execute_reply.started":"2022-04-21T14:50:40.629964Z","shell.execute_reply":"2022-04-21T14:50:40.635343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MRre.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:36:36.169037Z","iopub.execute_input":"2022-04-21T13:36:36.169322Z","iopub.status.idle":"2022-04-21T13:36:36.175157Z","shell.execute_reply.started":"2022-04-21T13:36:36.169291Z","shell.execute_reply":"2022-04-21T13:36:36.174369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predtionNF=Tuned.predict(MRre)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:50:44.341631Z","iopub.execute_input":"2022-04-21T14:50:44.342036Z","iopub.status.idle":"2022-04-21T14:50:44.389177Z","shell.execute_reply.started":"2022-04-21T14:50:44.342001Z","shell.execute_reply":"2022-04-21T14:50:44.388414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predtionNF","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:50:46.64001Z","iopub.execute_input":"2022-04-21T14:50:46.64029Z","iopub.status.idle":"2022-04-21T14:50:46.645884Z","shell.execute_reply.started":"2022-04-21T14:50:46.640259Z","shell.execute_reply":"2022-04-21T14:50:46.645115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (predtionNF>=0.5):\n    print('Predicted Class is FOOD')\n    print('Actual Class'+dic.get(Y_batch[j]))\n    grad_cam3=GradCam(Tuned,MRre,last_layer)\n    plt.imsave('./noods.png', MR)\n    img_path='./noods.png'\n    img = cv2.imread(img_path)\n    img = cv2.resize(img,(224,224),3)\n    grad_cam_supimpd3 = supimp(img, grad_cam443, 1.0, emphasize=False)\n    #grad_cam_supimpd3 = supimp(MR, grad_cam3, 0.5, emphasize=False)\n\n    plt.figure(figsize=(15, 15))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(MR)\n    #plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam3)\n    #plt.axis('off')\n    plt.title('Grad cam built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()\nelse:\n    print('Predicted Class is Non-FOOD')\n    print('Actual Class',dic.get(Y_batch[j]))\n    grad_cam3=GradCam(Tuned,MRre,last_layer)\n    grad_cam_supimpd3 = supimp(MR, grad_cam3, 0.5, emphasize=False)\n\n    plt.figure(figsize=(15, 15))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(MR)\n    #plt.axis('off')\n    plt.title('Original Image',)\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam3)\n    #plt.axis('off')\n    plt.title('Grad cam built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:51:17.905255Z","iopub.execute_input":"2022-04-21T14:51:17.905547Z","iopub.status.idle":"2022-04-21T14:51:18.953796Z","shell.execute_reply.started":"2022-04-21T14:51:17.905514Z","shell.execute_reply":"2022-04-21T14:51:18.953099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:00:29.295436Z","iopub.status.idle":"2022-04-21T10:00:29.29599Z","shell.execute_reply.started":"2022-04-21T10:00:29.295758Z","shell.execute_reply":"2022-04-21T10:00:29.295785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k=3\nMR2=X_batch[k]\nplt.imshow(MR2)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:52:34.147725Z","iopub.execute_input":"2022-04-21T14:52:34.147979Z","iopub.status.idle":"2022-04-21T14:52:34.577732Z","shell.execute_reply.started":"2022-04-21T14:52:34.14795Z","shell.execute_reply":"2022-04-21T14:52:34.577048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MRre2 = cv2.resize(MR2,(224,224))     # resize image to match model's expected sizing\nMRre2 = np.reshape(MRre2,[1,224,224,3]) \npredtionNF2=Tuned.predict(MRre2)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:52:38.20097Z","iopub.execute_input":"2022-04-21T14:52:38.201838Z","iopub.status.idle":"2022-04-21T14:52:38.262662Z","shell.execute_reply.started":"2022-04-21T14:52:38.201784Z","shell.execute_reply":"2022-04-21T14:52:38.261928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predtionNF2","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:52:41.333785Z","iopub.execute_input":"2022-04-21T14:52:41.334345Z","iopub.status.idle":"2022-04-21T14:52:41.339266Z","shell.execute_reply.started":"2022-04-21T14:52:41.334306Z","shell.execute_reply":"2022-04-21T14:52:41.338584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (predtionNF2>=0.5):\n    print('Predicted Class is FOOD')\n    print('Actual Class is ', dic.get(Y_batch[k]))\n    grad_cam443=GradCam(Tuned,MRre2,last_layer)\n    plt.imsave('./came.png', MR2)\n    img_path='./came.png'\n    img = cv2.imread(img_path)\n    img = cv2.resize(img,(224,224),3)\n    grad_cam_supimpd3 = supimp(img, grad_cam443, 1.0, emphasize=False)\n    #grad_cam_supimpd3 = supimp(MR2, grad_cam443, 0.1, emphasize=False)\n\n    plt.figure(figsize=(20, 20))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(MR2)\n    #plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    #plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()\nelse:\n    print('Predicted Class is NON FOOD')\n    print('Actual Class is ', dic.get(Y_batch[k]))\n    grad_cam443=GradCam(Tuned,MRre2,last_layer)\n    plt.imsave('./came.png', MR2)\n    img_path='./came.png'\n    img = cv2.imread(img_path)\n    img = cv2.resize(img,(224,224),3)\n    grad_cam_supimpd3 = supimp(img, grad_cam443, 1.0, emphasize=False)\n    plt.figure(figsize=(20, 20))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(MR2)\n    #plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    #plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:53:31.733504Z","iopub.execute_input":"2022-04-21T14:53:31.733764Z","iopub.status.idle":"2022-04-21T14:53:32.912751Z","shell.execute_reply.started":"2022-04-21T14:53:31.733732Z","shell.execute_reply":"2022-04-21T14:53:32.912099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k=15","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:53:39.178249Z","iopub.execute_input":"2022-04-21T14:53:39.178517Z","iopub.status.idle":"2022-04-21T14:53:39.184798Z","shell.execute_reply.started":"2022-04-21T14:53:39.178485Z","shell.execute_reply":"2022-04-21T14:53:39.183993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MR2=X_batch[k]\nplt.imshow(MR2)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:53:40.877646Z","iopub.execute_input":"2022-04-21T14:53:40.8779Z","iopub.status.idle":"2022-04-21T14:53:41.339569Z","shell.execute_reply.started":"2022-04-21T14:53:40.87787Z","shell.execute_reply":"2022-04-21T14:53:41.338953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MRre2 = cv2.resize(MR2,(224,224))     # resize image to match model's expected sizing\nMRre2 = np.reshape(MRre2,[1,224,224,3]) \npredtionNF2=Tuned.predict(MRre2)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:53:45.95873Z","iopub.execute_input":"2022-04-21T14:53:45.959277Z","iopub.status.idle":"2022-04-21T14:53:46.003599Z","shell.execute_reply.started":"2022-04-21T14:53:45.959242Z","shell.execute_reply":"2022-04-21T14:53:46.002884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predtionNF2","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:53:47.710485Z","iopub.execute_input":"2022-04-21T14:53:47.711035Z","iopub.status.idle":"2022-04-21T14:53:47.716283Z","shell.execute_reply.started":"2022-04-21T14:53:47.710997Z","shell.execute_reply":"2022-04-21T14:53:47.715531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (predtionNF2>=0.5):\n    print('Predicted Class is FOOD')\n    print('Actual Class is ', dic.get(Y_batch[k]))\n    grad_cam443=GradCam(Tuned,MRre2,last_layer)\n    \n    grad_cam_supimpd3 = supimp(MR2, grad_cam443, 1.5, emphasize=False)\n\n    plt.figure(figsize=(20, 20))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(MR2)\n    #plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    #plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()\nelse:\n    print('Predicted Class is NON FOOD')\n    print('Actual Class is ', dic.get(Y_batch[k]))\n    grad_cam443=GradCam(Tuned,MRre2,last_layer)\n    plt.imsave('./cheval.png', MR2)\n    img_path='./cheval.png'\n    img = cv2.imread(img_path)\n    img = cv2.resize(img,(224,224),3)\n    grad_cam_supimpd3 = supimp(img, grad_cam443, 1.0, emphasize=False)\n    #grad_cam_supimpd3 = supimp(MR2, grad_cam443, 1.5, emphasize=False)\n\n    plt.figure(figsize=(20, 20))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(MR2)\n    #plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    #plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:54:34.345894Z","iopub.execute_input":"2022-04-21T14:54:34.346157Z","iopub.status.idle":"2022-04-21T14:54:35.516723Z","shell.execute_reply.started":"2022-04-21T14:54:34.346125Z","shell.execute_reply":"2022-04-21T14:54:35.516062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's visualize the testset\n\nplt.figure(figsize=(15, 15)) #image displayed in size 15X15\nfor i in range(0, 10):\n    plt.subplot(2, 5, i+1) #2 rows with 5 images per row\n    for x, y in testset:\n        image = x[0]        \n        dic = {1:'food', 0:'non-food'} \n        plt.title(dic.get(y[0]))\n        plt.axis('off')\n        plt.imshow(np.squeeze(image),interpolation='nearest') # nearest will display an image without trying to interpolate between pixels since output display resolution != image resolution\n        break\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:00:29.334089Z","iopub.status.idle":"2022-04-21T10:00:29.334719Z","shell.execute_reply.started":"2022-04-21T10:00:29.334489Z","shell.execute_reply":"2022-04-21T10:00:29.334513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FD=11\nplt.imshow(x[FD])\nplt.title(dic.get(y[FD]))","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:41:46.136681Z","iopub.execute_input":"2022-04-21T13:41:46.137077Z","iopub.status.idle":"2022-04-21T13:41:46.606613Z","shell.execute_reply.started":"2022-04-21T13:41:46.137041Z","shell.execute_reply":"2022-04-21T13:41:46.605849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_array3=x[FD]\nimg2 = cv2.resize(img_array3,(224,224))     # resize image to match model's expected sizing\nimg2 = np.reshape(img_array3,[1,224,224,3]) ","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:41:50.117789Z","iopub.execute_input":"2022-04-21T13:41:50.118328Z","iopub.status.idle":"2022-04-21T13:41:50.124953Z","shell.execute_reply.started":"2022-04-21T13:41:50.118288Z","shell.execute_reply":"2022-04-21T13:41:50.123529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preFD=Tuned.predict(img2)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:41:52.458776Z","iopub.execute_input":"2022-04-21T13:41:52.459027Z","iopub.status.idle":"2022-04-21T13:41:52.503032Z","shell.execute_reply.started":"2022-04-21T13:41:52.458998Z","shell.execute_reply":"2022-04-21T13:41:52.502381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preFD","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:41:55.483609Z","iopub.execute_input":"2022-04-21T13:41:55.483877Z","iopub.status.idle":"2022-04-21T13:41:55.489713Z","shell.execute_reply.started":"2022-04-21T13:41:55.483848Z","shell.execute_reply":"2022-04-21T13:41:55.488982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:00:29.350113Z","iopub.status.idle":"2022-04-21T10:00:29.350492Z","shell.execute_reply.started":"2022-04-21T10:00:29.350301Z","shell.execute_reply":"2022-04-21T10:00:29.350321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (preFD>=0.5):\n    print('Predicted Class is FOOD')\n    print('{:.2%} probability of being  Food case'.format(preFD[0][0]))\n    print('Actual Class is ', dic.get(y[FD]))\n    grad_cam443=GradCam(Tuned,img2,last_layer)\n    grad_cam_supimpd3 = supimp(img_array3, grad_cam443, 0.1, emphasize=False)\n\n    plt.figure(figsize=(20, 20))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(img_array3)\n    #plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    #plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()\nelse:\n    print('Predicted Class is NON FOOD')\n    print('{:.2%} probability of being NON Food case'.format(1-preFD[0][0]))\n    print('Actual Class is ', dic.get(y[FD]))\n    grad_cam443=GradCam(Tuned,img2,last_layer)\n    grad_cam_supimpd3 = supimp(img_array3, grad_cam443, 0.1, emphasize=False)\n\n    plt.figure(figsize=(20, 20))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(img_array3)\n    #plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    #plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:42:59.071921Z","iopub.execute_input":"2022-04-21T13:42:59.072533Z","iopub.status.idle":"2022-04-21T13:43:00.075651Z","shell.execute_reply.started":"2022-04-21T13:42:59.072494Z","shell.execute_reply":"2022-04-21T13:43:00.07503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:43:46.286447Z","iopub.execute_input":"2022-04-21T13:43:46.287006Z","iopub.status.idle":"2022-04-21T13:43:46.299893Z","shell.execute_reply.started":"2022-04-21T13:43:46.286963Z","shell.execute_reply":"2022-04-21T13:43:46.298884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NFD=0\nplt.imshow(X_batch[NFD])\nplt.title(dic.get(Y_batch[NFD]))","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:45:23.832647Z","iopub.execute_input":"2022-04-21T13:45:23.833403Z","iopub.status.idle":"2022-04-21T13:45:24.274575Z","shell.execute_reply.started":"2022-04-21T13:45:23.833365Z","shell.execute_reply":"2022-04-21T13:45:24.273237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_array4=X_batch[NFD]\nimg3 = cv2.resize(img_array4,(224,224))     # resize image to match model's expected sizing\nimg3 = np.reshape(img_array4,[1,224,224,3]) ","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:37:12.836608Z","iopub.execute_input":"2022-04-21T14:37:12.83703Z","iopub.status.idle":"2022-04-21T14:37:12.841942Z","shell.execute_reply.started":"2022-04-21T14:37:12.836994Z","shell.execute_reply":"2022-04-21T14:37:12.841262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preNFD=Tuned.predict(img3)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:37:14.436418Z","iopub.execute_input":"2022-04-21T14:37:14.437121Z","iopub.status.idle":"2022-04-21T14:37:14.747592Z","shell.execute_reply.started":"2022-04-21T14:37:14.437083Z","shell.execute_reply":"2022-04-21T14:37:14.746843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preNFD","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:37:15.977331Z","iopub.execute_input":"2022-04-21T14:37:15.977994Z","iopub.status.idle":"2022-04-21T14:37:15.984102Z","shell.execute_reply.started":"2022-04-21T14:37:15.977957Z","shell.execute_reply":"2022-04-21T14:37:15.98323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (preNFD>=0.5):\n    print('Predicted Class is FOOD')\n    print('{:.2%} probability of being  Food case'.format(preNFD[0][0]))\n    print('Actual Class is ', dic.get(Y_batch[NFD]))\n    grad_cam443=GradCam(Tuned,img3,last_layer)\n    plt.imsave('./Painchoc.png', img_array4)\n    img_path='./Painchoc.png'\n    img = cv2.imread(img_path)\n    img = cv2.resize(img,(224,224),3)\n    grad_cam_supimpd3 = supimp(img, grad_cam443, 1.0, emphasize=False)\n    #grad_cam_supimpd3 = supimp(img, grad_cam443, 1.0, emphasize=False)\n\n    plt.figure(figsize=(20, 20))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(img_array4)\n    #plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    #plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()\nelse:\n    print('Predicted Class is NON FOOD')\n    print('{:.2%} probability of being NON Food case'.format(1-preNFD[0][0]))\n    print('Actual Class is ', dic.get(y[NFD]))\n    grad_cam443=GradCam(Tuned,img3,last_layer)\n    grad_cam_supimpd3 = supimp(img_array4, grad_cam443, 0.1, emphasize=False)\n\n    plt.figure(figsize=(10, 10))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(img_array4)\n    plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:48:36.195262Z","iopub.execute_input":"2022-04-21T14:48:36.195568Z","iopub.status.idle":"2022-04-21T14:48:37.326484Z","shell.execute_reply.started":"2022-04-21T14:48:36.195533Z","shell.execute_reply":"2022-04-21T14:48:37.325844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img_array4)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:37:42.929812Z","iopub.execute_input":"2022-04-21T14:37:42.930075Z","iopub.status.idle":"2022-04-21T14:37:43.348634Z","shell.execute_reply.started":"2022-04-21T14:37:42.930044Z","shell.execute_reply":"2022-04-21T14:37:43.348018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_builder = keras.applications.xception.Xception\nimg_size = (224, 224)\npreprocess_input = keras.applications.xception.preprocess_input\n#decode_predictions = keras.applications.xception.decode_predictions\n#img_array = preprocess_input(get_img_array(img_path, size=img_size))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:37:52.623245Z","iopub.execute_input":"2022-04-21T14:37:52.623505Z","iopub.status.idle":"2022-04-21T14:37:52.627325Z","shell.execute_reply.started":"2022-04-21T14:37:52.623477Z","shell.execute_reply":"2022-04-21T14:37:52.626642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_layer","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:37:55.850681Z","iopub.execute_input":"2022-04-21T14:37:55.851352Z","iopub.status.idle":"2022-04-21T14:37:55.857077Z","shell.execute_reply.started":"2022-04-21T14:37:55.851315Z","shell.execute_reply":"2022-04-21T14:37:55.856284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grad_cam443=GradCam(Tuned,img3,last_layer)\n#grad_cam_supimpd3 = supimp(img_array, grad_cam443, 1.0, emphasize=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:37:57.545535Z","iopub.execute_input":"2022-04-21T14:37:57.545786Z","iopub.status.idle":"2022-04-21T14:37:57.573014Z","shell.execute_reply.started":"2022-04-21T14:37:57.545758Z","shell.execute_reply":"2022-04-21T14:37:57.572394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grad_cam443.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:38:04.483745Z","iopub.execute_input":"2022-04-21T14:38:04.483996Z","iopub.status.idle":"2022-04-21T14:38:04.488925Z","shell.execute_reply.started":"2022-04-21T14:38:04.483965Z","shell.execute_reply":"2022-04-21T14:38:04.488073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preFD=Tuned.predict(img2)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:23:36.915927Z","iopub.execute_input":"2022-04-21T14:23:36.916179Z","iopub.status.idle":"2022-04-21T14:23:36.960795Z","shell.execute_reply.started":"2022-04-21T14:23:36.916149Z","shell.execute_reply":"2022-04-21T14:23:36.9601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_array = preprocess_input(get_img_array(img_path, size=img_size))","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:23:38.834542Z","iopub.execute_input":"2022-04-21T14:23:38.83507Z","iopub.status.idle":"2022-04-21T14:23:38.843965Z","shell.execute_reply.started":"2022-04-21T14:23:38.835034Z","shell.execute_reply":"2022-04-21T14:23:38.843253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (preFD>=0.5):\n    print('Predicted Class is FOOD')\n    print('{:.2%} probability of being  Food case'.format(preFD[0][0]))\n    print('Actual Class is ', dic.get(y[FD]))\n    grad_cam443=GradCam(Tuned,img2,last_layer)\n    grad_cam_supimpd3 = supimp(img_array3, grad_cam443, 0.1, emphasize=False)\n\n    plt.figure(figsize=(20, 20))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(img_array3)\n    #plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    #plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()\nelse:\n    print('Predicted Class is NON FOOD')\n    print('{:.2%} probability of being NON Food case'.format(1-preFD[0][0]))\n    print('Actual Class is ', dic.get(y[FD]))\n    grad_cam443=GradCam(Tuned,img2,last_layer)\n    plt.imsave('./Guitare.png', img_array3)\n    img_path='./Guitare.png'\n    img = cv2.imread(img_path)\n    img = cv2.resize(img,(224,224),3)\n    grad_cam_supimpd3 = supimp(img, grad_cam443, 1.0, emphasize=False)\n\n    plt.figure(figsize=(20, 20))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(img_array3)\n    #plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    #plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:46:36.886845Z","iopub.execute_input":"2022-04-21T14:46:36.887112Z","iopub.status.idle":"2022-04-21T14:46:37.94965Z","shell.execute_reply.started":"2022-04-21T14:46:36.887083Z","shell.execute_reply":"2022-04-21T14:46:37.949041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#img_array = preprocess_input(get_img_array(img_path, size=img_size))","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:26:03.11559Z","iopub.execute_input":"2022-04-21T14:26:03.115855Z","iopub.status.idle":"2022-04-21T14:26:03.123428Z","shell.execute_reply.started":"2022-04-21T14:26:03.115826Z","shell.execute_reply":"2022-04-21T14:26:03.122664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#img_array = preprocess_input(get_img_array(img_path, size=img_size))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k=30\nMR2=X_batch[k]\nplt.imshow(MR2)\n\nMRre2 = cv2.resize(MR2,(224,224))     # resize image to match model's expected sizing\nMRre2 = np.reshape(MRre2,[1,224,224,3]) \npredtionNF2=Tuned.predict(MRre2)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:42:46.399034Z","iopub.execute_input":"2022-04-21T14:42:46.399332Z","iopub.status.idle":"2022-04-21T14:42:46.868599Z","shell.execute_reply.started":"2022-04-21T14:42:46.3993Z","shell.execute_reply":"2022-04-21T14:42:46.867878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (predtionNF2>=0.5):\n    print('Predicted Class is FOOD')\n    print('Actual Class is ', dic.get(Y_batch[k]))\n    grad_cam443=GradCam(Tuned,MRre2,last_layer)\n    grad_cam_supimpd3 = supimp(MR2, grad_cam443, 0.1, emphasize=False)\n\n    plt.figure(figsize=(20, 20))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(MR2)\n    #plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    #plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()\nelse:\n    print('Predicted Class is NON FOOD')\n    print('Actual Class is ', dic.get(Y_batch[k]))\n    grad_cam443=GradCam(Tuned,MRre2,last_layer)\n    plt.imsave('./Ciel.png', MR2)\n    img_path='./Ciel.png'\n    #display(Image.open(img_path))\n    #grad_cam443=GradCam(Tuned,MRre2,last_layer)\n    img = cv2.imread(img_path)\n    img = cv2.resize(img,(224,224),3)\n    grad_cam_supimpd3 = supimp(img, grad_cam443, 1.0, emphasize=False)\n    plt.figure(figsize=(20, 20))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(MR2)\n    #plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    #plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:45:08.671955Z","iopub.execute_input":"2022-04-21T14:45:08.672237Z","iopub.status.idle":"2022-04-21T14:45:09.852356Z","shell.execute_reply.started":"2022-04-21T14:45:08.672198Z","shell.execute_reply":"2022-04-21T14:45:09.851725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NFD=31\nplt.imshow(X_batch[NFD])\nplt.title(dic.get(Y_batch[NFD]))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:56:34.196423Z","iopub.execute_input":"2022-04-21T14:56:34.196737Z","iopub.status.idle":"2022-04-21T14:56:34.671689Z","shell.execute_reply.started":"2022-04-21T14:56:34.196693Z","shell.execute_reply":"2022-04-21T14:56:34.669875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_array4=X_batch[NFD]\nimg3 = cv2.resize(img_array4,(224,224))     # resize image to match model's expected sizing\nimg3 = np.reshape(img_array4,[1,224,224,3]) ","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:56:46.599358Z","iopub.execute_input":"2022-04-21T14:56:46.599615Z","iopub.status.idle":"2022-04-21T14:56:46.604079Z","shell.execute_reply.started":"2022-04-21T14:56:46.599585Z","shell.execute_reply":"2022-04-21T14:56:46.603384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preNFD=Tuned.predict(img3)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:57:07.650973Z","iopub.execute_input":"2022-04-21T14:57:07.651309Z","iopub.status.idle":"2022-04-21T14:57:07.696868Z","shell.execute_reply.started":"2022-04-21T14:57:07.651253Z","shell.execute_reply":"2022-04-21T14:57:07.696218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (preNFD>=0.5):\n    print('Predicted Class is FOOD')\n    print('{:.2%} probability of being  Food case'.format(preNFD[0][0]))\n    print('Actual Class is ', dic.get(Y_batch[NFD]))\n    grad_cam443=GradCam(Tuned,img3,last_layer)\n    plt.imsave('./macaroni.png', img_array4)\n    img_path='./macaroni.png'\n    img = cv2.imread(img_path)\n    img = cv2.resize(img,(224,224),3)\n    grad_cam_supimpd3 = supimp(img, grad_cam443, 1.0, emphasize=False)\n    #grad_cam_supimpd3 = supimp(img, grad_cam443, 1.0, emphasize=False)\n\n    plt.figure(figsize=(20, 20))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(img_array4)\n    #plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    #plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    #plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()\nelse:\n    print('Predicted Class is NON FOOD')\n    print('{:.2%} probability of being NON Food case'.format(1-preNFD[0][0]))\n    print('Actual Class is ', dic.get(y[NFD]))\n    grad_cam443=GradCam(Tuned,img3,last_layer)\n    grad_cam_supimpd3 = supimp(img_array4, grad_cam443, 0.1, emphasize=False)\n\n    plt.figure(figsize=(10, 10))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(img_array4)\n    plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:57:19.111583Z","iopub.execute_input":"2022-04-21T14:57:19.11185Z","iopub.status.idle":"2022-04-21T14:57:20.288693Z","shell.execute_reply.started":"2022-04-21T14:57:19.111821Z","shell.execute_reply":"2022-04-21T14:57:20.288038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NFD=23\nplt.imshow(X_batch[NFD])\nplt.title(dic.get(Y_batch[NFD]))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:59:23.030451Z","iopub.execute_input":"2022-04-21T14:59:23.030985Z","iopub.status.idle":"2022-04-21T14:59:23.580031Z","shell.execute_reply.started":"2022-04-21T14:59:23.030949Z","shell.execute_reply":"2022-04-21T14:59:23.579269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_array4=X_batch[NFD]\nimg3 = cv2.resize(img_array4,(224,224))     # resize image to match model's expected sizing\nimg3 = np.reshape(img_array4,[1,224,224,3]) ","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:59:26.452444Z","iopub.execute_input":"2022-04-21T14:59:26.452699Z","iopub.status.idle":"2022-04-21T14:59:26.457716Z","shell.execute_reply.started":"2022-04-21T14:59:26.45267Z","shell.execute_reply":"2022-04-21T14:59:26.456968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preNFD=Tuned.predict(img3)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:59:28.585325Z","iopub.execute_input":"2022-04-21T14:59:28.585875Z","iopub.status.idle":"2022-04-21T14:59:28.646697Z","shell.execute_reply.started":"2022-04-21T14:59:28.585837Z","shell.execute_reply":"2022-04-21T14:59:28.646019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (preNFD>=0.5):\n    print('Predicted Class is FOOD')\n    print('{:.2%} probability of being  Food case'.format(preNFD[0][0]))\n    print('Actual Class is ', dic.get(Y_batch[NFD]))\n    grad_cam443=GradCam(Tuned,img3,last_layer)\n    plt.imsave('./cafe.png', img_array4)\n    img_path=('./cafe.png')\n    img = cv2.imread(img_path)\n    img = cv2.resize(img,(224,224),3)\n    grad_cam_supimpd3 = supimp(img, grad_cam443, 1.0, emphasize=False)\n    #grad_cam_supimpd3 = supimp(img, grad_cam443, 1.0, emphasize=False)\n\n    plt.figure(figsize=(20, 20))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(img_array4)\n    plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()\nelse:\n    print('Predicted Class is NON FOOD')\n    print('{:.2%} probability of being NON Food case'.format(1-preNFD[0][0]))\n    print('Actual Class is ', dic.get(y[NFD]))\n    grad_cam443=GradCam(Tuned,img3,last_layer)\n    grad_cam_supimpd3 = supimp(img_array4, grad_cam443, 0.1, emphasize=False)\n\n    plt.figure(figsize=(10, 10))\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(img_array4)\n    plt.axis('off')\n    plt.title('Original Image')\n    ax = plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam443)\n    plt.axis('off')\n    plt.title('Grad Cam Image built')\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(grad_cam_supimpd3)\n    plt.axis('off')\n    plt.title('Last CONV Grad-CAM heat-map')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:47:21.860326Z","iopub.execute_input":"2022-04-21T15:47:21.860944Z","iopub.status.idle":"2022-04-21T15:47:22.922549Z","shell.execute_reply.started":"2022-04-21T15:47:21.860906Z","shell.execute_reply":"2022-04-21T15:47:22.921216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"END\")","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:52:56.124509Z","iopub.execute_input":"2022-04-21T15:52:56.124927Z","iopub.status.idle":"2022-04-21T15:52:56.129913Z","shell.execute_reply.started":"2022-04-21T15:52:56.124881Z","shell.execute_reply":"2022-04-21T15:52:56.129171Z"},"trusted":true},"execution_count":null,"outputs":[]}]}